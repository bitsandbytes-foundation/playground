============================= test session starts ==============================
platform linux -- Python 3.10.0, pytest-8.3.2, pluggy-1.5.0 -- /home/sdp/.condax/mamba/envs/bnb_cpu/bin/python3.10
cachedir: .pytest_cache
rootdir: /home/sdp/src/transformers
configfile: pyproject.toml
collecting ... collected 43 items

tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_bnb_4bit_wrong_config PASSED [  2%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_device_and_dtype_assignment PASSED [  4%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_fp32_4bit_conversion PASSED [  6%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_generate_quality PASSED [  9%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_generate_quality_config PASSED [ 11%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_generate_quality_dequantize PASSED [ 13%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_linear_are_4bit PASSED [ 16%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_memory_footprint PASSED [ 18%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_original_dtype PASSED [ 20%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_quantization_config_json_serialization PASSED [ 23%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_quantization_num_parameters PASSED [ 25%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_rwkv_4bit SKIPPED [ 27%]
tests/quantization/bnb/test_4bit.py::Bnb4BitT5Test::test_inference_with_keep_in_fp32 PASSED [ 30%]
tests/quantization/bnb/test_4bit.py::Bnb4BitT5Test::test_inference_without_keep_in_fp32 PASSED [ 32%]
tests/quantization/bnb/test_4bit.py::Classes4BitModelTest::test_correct_head_class PASSED [ 34%]
tests/quantization/bnb/test_4bit.py::Pipeline4BitTest::test_pipeline PASSED [ 37%]
tests/quantization/bnb/test_4bit.py::Bnb4bitTestMultiGpu::test_multi_gpu_loading SKIPPED [ 39%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTestTraining::test_training PASSED [ 41%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_bnb_4bit_wrong_config PASSED [ 44%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_device_and_dtype_assignment PASSED [ 46%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_fp32_4bit_conversion PASSED [ 48%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_generate_quality PASSED [ 51%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_generate_quality_config PASSED [ 53%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_generate_quality_dequantize PASSED [ 55%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_linear_are_4bit PASSED [ 58%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_memory_footprint PASSED [ 60%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_original_dtype PASSED [ 62%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_quantization_config_json_serialization PASSED [ 65%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_quantization_num_parameters PASSED [ 67%]
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_rwkv_4bit SKIPPED [ 69%]
tests/quantization/bnb/test_4bit.py::BaseSerializationTest::test_serialization SKIPPED [ 72%]
tests/quantization/bnb/test_4bit.py::ExtendedSerializationTest::test_fp4_double_safe SKIPPED [ 74%]
tests/quantization/bnb/test_4bit.py::ExtendedSerializationTest::test_fp4_double_unsafe SKIPPED [ 76%]
tests/quantization/bnb/test_4bit.py::ExtendedSerializationTest::test_fp4_single_safe PASSED [ 79%]
tests/quantization/bnb/test_4bit.py::ExtendedSerializationTest::test_fp4_single_unsafe PASSED [ 81%]
tests/quantization/bnb/test_4bit.py::ExtendedSerializationTest::test_nf4_double_unsafe SKIPPED [ 83%]
tests/quantization/bnb/test_4bit.py::ExtendedSerializationTest::test_nf4_single_safe FAILED [ 86%]
tests/quantization/bnb/test_4bit.py::ExtendedSerializationTest::test_nf4_single_unsafe FAILED [ 88%]
tests/quantization/bnb/test_4bit.py::ExtendedSerializationTest::test_serialization SKIPPED [ 90%]
tests/quantization/bnb/test_4bit.py::BloomSerializationTest::test_serialization SKIPPED [ 93%]
tests/quantization/bnb/test_4bit.py::GPTSerializationTest::test_serialization SKIPPED [ 95%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTestBasicConfigTest::test_load_in_4_and_8_bit_fails PASSED [ 97%]
tests/quantization/bnb/test_4bit.py::Bnb4BitTestBasicConfigTest::test_set_load_in_8_bit PASSED [100%]

=================================== FAILURES ===================================
________________ ExtendedSerializationTest.test_nf4_single_safe ________________

self = <bnb.test_4bit.ExtendedSerializationTest testMethod=test_nf4_single_safe>

    def test_nf4_single_safe(self):
>       self.test_serialization(quant_type="nf4", double_quant=False, safe_serialization=True)

tests/quantization/bnb/test_4bit.py:669: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/transformers/testing_utils.py:334: in wrapper
    return test_func(*args, **kwargs)
src/transformers/testing_utils.py:334: in wrapper
    return test_func(*args, **kwargs)
tests/quantization/bnb/test_4bit.py:624: in test_serialization
    self.assertTrue(d0[k].dtype == d1[k].dtype)
E   AssertionError: False is not true
----------------------------- Captured stderr call -----------------------------
Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
_______________ ExtendedSerializationTest.test_nf4_single_unsafe _______________

self = <bnb.test_4bit.ExtendedSerializationTest testMethod=test_nf4_single_unsafe>

    def test_nf4_single_unsafe(self):
>       self.test_serialization(quant_type="nf4", double_quant=False, safe_serialization=False)

tests/quantization/bnb/test_4bit.py:666: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src/transformers/testing_utils.py:334: in wrapper
    return test_func(*args, **kwargs)
src/transformers/testing_utils.py:334: in wrapper
    return test_func(*args, **kwargs)
tests/quantization/bnb/test_4bit.py:624: in test_serialization
    self.assertTrue(d0[k].dtype == d1[k].dtype)
E   AssertionError: False is not true
----------------------------- Captured stderr call -----------------------------
Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.
=============================== warnings summary ===============================
../../.condax/mamba/envs/bnb_cpu/lib/python3.10/site-packages/intel_extension_for_pytorch/nn/utils/_weight_prepack.py:5
  /home/sdp/.condax/mamba/envs/bnb_cpu/lib/python3.10/site-packages/intel_extension_for_pytorch/nn/utils/_weight_prepack.py:5: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html
    import pkg_resources

tests/quantization/bnb/test_4bit.py: 39 warnings
  /home/sdp/src/bnb/bitsandbytes/backends/cpu_xpu_common.py:317: UserWarning: fp4 quantization is currently slow on CPU/XPU. Please Use nf4 instead for better performance.
    warnings.warn("fp4 quantization is currently slow on CPU/XPU. Please Use nf4 instead for better performance.")

tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_bnb_4bit_wrong_config
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_rwkv_4bit
tests/quantization/bnb/test_4bit.py::BaseSerializationTest::test_serialization
  /home/sdp/.condax/mamba/envs/bnb_cpu/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    return torch.load(io.BytesIO(b))

tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_generate_quality
tests/quantization/bnb/test_4bit.py::Bnb4BitTest::test_generate_quality_config
tests/quantization/bnb/test_4bit.py::Bnb4BitT5Test::test_inference_with_keep_in_fp32
tests/quantization/bnb/test_4bit.py::Bnb4BitT5Test::test_inference_without_keep_in_fp32
tests/quantization/bnb/test_4bit.py::Bnb4BitTestTraining::test_training
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_generate_quality
tests/quantization/bnb/test_4bit.py::Bnb4BitGPT2Test::test_generate_quality_config
  /home/sdp/src/bnb/bitsandbytes/nn/modules.py:437: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.
    warnings.warn(

tests/quantization/bnb/test_4bit.py::Bnb4BitT5Test::test_inference_with_keep_in_fp32
tests/quantization/bnb/test_4bit.py::Bnb4BitT5Test::test_inference_with_keep_in_fp32
tests/quantization/bnb/test_4bit.py::Bnb4BitT5Test::test_inference_without_keep_in_fp32
tests/quantization/bnb/test_4bit.py::Bnb4BitT5Test::test_inference_without_keep_in_fp32
  /home/sdp/src/transformers/src/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
    warnings.warn(

tests/quantization/bnb/test_4bit.py::Bnb4BitT5Test::test_inference_with_keep_in_fp32
tests/quantization/bnb/test_4bit.py::Bnb4BitT5Test::test_inference_without_keep_in_fp32
  /home/sdp/src/bnb/bitsandbytes/nn/modules.py:432: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference.
    warnings.warn(

tests/quantization/bnb/test_4bit.py: 23 warnings
  /home/sdp/src/transformers/src/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
    warnings.warn(

tests/quantization/bnb/test_4bit.py::Bnb4BitTestTraining::test_training
  /home/sdp/.condax/mamba/envs/bnb_cpu/lib/python3.10/site-packages/torch/autograd/graph.py:768: UserWarning: aten::layer_norm: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
SKIPPED [2] tests/quantization/bnb/test_4bit.py:199: Test skipped due to NotImplementedError: bnb_4bit_use_double_quant is not supported yet for CPU/XPU
SKIPPED [1] tests/quantization/bnb/test_4bit.py:488: test requires multiple GPUs
SKIPPED [4] tests/quantization/bnb/test_4bit.py:578: Test skipped due to NotImplementedError: bnb_4bit_use_double_quant is not supported yet for CPU/XPU
SKIPPED [1] tests/quantization/bnb/test_4bit.py:685: Test skipped due to NotImplementedError: bnb_4bit_use_double_quant is not supported yet for CPU/XPU
SKIPPED [1] tests/quantization/bnb/test_4bit.py:682: Test skipped due to NotImplementedError: bnb_4bit_use_double_quant is not supported yet for CPU/XPU
SKIPPED [1] tests/quantization/bnb/test_4bit.py:671: Test skipped due to NotImplementedError: bnb_4bit_use_double_quant is not supported yet for CPU/XPU
====== 2 failed, 31 passed, 10 skipped, 80 warnings in 215.67s (0:03:35) =======
